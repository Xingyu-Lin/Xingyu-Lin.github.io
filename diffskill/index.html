<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools">
    <meta name="author" content="Xingyu Lin, Zhiao Huang, Yunzhu Li, Joshua B. Tenenbaum, David Held, Chuang Gan">

    <title>DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with
        Tools</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--        <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>DiffSkill: Skill Abstraction from Differentiable Physics <br> for Deformable Object Manipulations with Tools
    </h2>
    <h3>ICLR 2022</h3>
    <!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p class="authors">
        <a href="hhttps://xingyu-lin.github.io/"> Xingyu Lin</a>,
        <a href="https://sites.google.com/view/zhiao-huang"> Zhiao Huang</a>,
        <a href="http://people.csail.mit.edu/liyunzhu/"> Yunzhu Li</a>,
        <a href="http://web.mit.edu/cocosci/josh.html"> Joshua B. Tenenbaum</a>,
        <a href="https://davheld.github.io/"> David Held</a>,
        <a href="https://people.csail.mit.edu/ganchuang/"> Chuang Gan</a>
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://openreview.net/pdf?id=Kef8cKdHWpP">Paper</a>
        <a class="btn btn-primary" href="https://github.com/Xingyu-Lin/DiffSkill">Code (Coming soon)</a>
        <!--        <a class="btn btn-primary" href="https://drive.google.com/drive/u/1/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K">Data</a>-->
    </div>
</div>

<div class="container">
    <div class="section">
        <!--        Add video later-->
        <!--        <div class="vcontainer">-->
        <!--            <iframe class='video' src="https://www.youtube.com/embed/Q2fLWGBeaiI" frameborder="0"-->
        <!--                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"-->
        <!--                    allowfullscreen></iframe>-->
        <!--        </div>-->
        <!--        <hr>-->
        <div class="container">
            <img src="img/pull.jpg" style="width:100%">
        </div>
        <hr>
        <p>
            We consider the problem of sequential robotic manipulation of deformable objects using tools.
            Previous works have shown that differentiable physics simulators provide gradients to the environment state
            and help trajectory optimization to converge orders of magnitude faster than model-free reinforcement
            learning algorithms for deformable object manipulation. However, such gradient-based trajectory optimization
            typically requires access to the full simulator states and can only solve short-horizon, single-skill tasks
            due to local optima. In this work, we propose a novel framework, named DiffSkill, that uses a differentiable
            physics simulator for skill abstraction to solve long-horizon deformable object manipulation tasks from
            sensory observations. In particular, \rebuttal{we first obtain short-horizon skills using individual tools
            from a gradient-based optimizer, using the full state information in a differentiable simulator; we then
            learn a neural skill abstractor from the demonstration trajectories which takes RGBD images as input.
            Finally, we plan over the skills by finding the intermediate goals and then solve long-horizon tasks}. We
            show the advantages of our method in a new set of sequential deformable object manipulation tasks compared
            to previous reinforcement learning algorithms and compared to the trajectory optimizer.
        </p>
    </div>

    <div class="section">
        <h2>Task1: Lift and Spread</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col-md-8">
                <p>
                    The task is to first lift the dough onto the cutting board and then spread it using a rolling pin.
                </p>
                <p>
                    Left below shows the plan generated by DiffSkill and the right shows the execution of the plan. The red line shows the
                    normalized performance, while the green line shows the success threshold of the task.
                </p>
                <div class="col justify-content-center text-center">
                    <h5>DiffSkill Generated plan</h5>
                </div>

                <img src="img/plan_lift_new.png" style="width:100%">
            </div>
            <div class="col-md-4">
                <div class="col justify-content-center text-center">
                    <h5>DiffSkill Execution</h5>
                    <img src="img/diffskill_execute_0_plot.gif" style="width:100%">
                </div>
            </div>
        </div>
        <p></p>
<!--        <hr>-->
        <div class="col justify-content-center text-center">
            <h3>Compare with baselines</h3>
        </div>
        <div class="row align-items-center">
            <div class="col-md-6">
                <div class="col justify-content-center text-center">
                <h5>Model-free RL (SAC)</h5>
                    <div class="row align-items-center">
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/lift_traj_opt_tool_a.gif" style="width:100%">
                            <h6>Tool A only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/lift_traj_opt_tool_b.gif" style="width:100%">
                            <h6>Tool B only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/lift_traj_opt_tool_ab.gif" style="width:100%">
                            <h6>Multi-tool</h6>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="col justify-content-center text-center">
                    <h5>Trajectory Optimizer (Oracle)</h5>
                    <div class="row align-items-center">
                        <div class="col-md-4">
                            <img src="img/baseline_sac/lift_sac_tool_a.gif" style="width:100%">
                            <h6>Tool A only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_sac/lift_sac_tool_b.gif" style="width:100%">
                            <h6>Tool B only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_sac/lift_sac_tool_ab.gif" style="width:100%">
                            <h6>Multi-tool</h6>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>Task2: Gather and transport</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col-md-8">
                <p>
                    The task is to first gather the scatthered dough and then trasport it onto the cutting board.
                </p>
                <p>
                    Left below shows the plan generated by DiffSkill and the right shows the execution of the plan. The red line shows the
                    normalized performance, while the green line shows the success threshold of the task.
                </p>
                <div class="col-md-10">
                    <div class="col justify-content-center text-center">
                        <h5>DiffSkill Generated plan</h5>
                    </div>
                </div>
                <img src="img/plan_gather_new.png" style="width:80%">
            </div>
            <div class="col-md-4">
                <div class="col justify-content-center text-center">
                    <h5>DiffSkill Execution</h5>
                    <img src="img/diffskill_execute_1_plot.gif" style="width:100%">
                </div>
            </div>
        </div>
        <p></p>
        <div class="col justify-content-center text-center">
            <h3>Compare with baselines</h3>
        </div>
        <div class="row align-items-center">
            <div class="col-md-6">
                <div class="col justify-content-center text-center">
                    <h5>Model-free RL (SAC)</h5>
                    <div class="row align-items-center">
                        <div class="col-md-4">
                            <img src="img/baseline_sac/gather_sac_tool_a.gif" style="width:100%">
                            <h6>Tool A only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_sac/gather_sac_tool_b.gif" style="width:100%">
                            <h6>Tool B only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_sac/gather_sac_tool_ab.gif" style="width:100%">
                            <h6>Multi-tool</h6>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="col justify-content-center text-center">
                    <h5>Trajectory Optimizer (Oracle)</h5>
                    <div class="row align-items-center">
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/gather_traj_opt_tool_a.gif" style="width:100%">
                            <h6>Tool A only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/gather_traj_opt_tool_b.gif" style="width:100%">
                            <h6>Tool B only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/gather_traj_opt_tool_ab.gif" style="width:100%">
                            <h6>Multi-tool</h6>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="section">
        <h2>Task3: Cut and rearrange</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col-md-8">
                <p>
                    The task is to first cut the dough using the knife and the transport each part to targeted locations
                </p>
                <p>
                    Left below shows the plan generated by DiffSkill and the right shows the execution of the plan. The red line shows the
                    normalized performance, while the green line shows the success threshold of the task.
                </p>
                <div class="col-md-12">
                    <div class="col justify-content-center text-center">
                        <h5>DiffSkill Generated plan</h5>
                    </div>
                </div>
                <img src="img/plan_cut_new.png" style="width:100%">
            </div>
            <div class="col-md-4">
                <div class="col justify-content-center text-center">
                    <h5>DiffSkill Execution</h5>
                    <img src="img/diffskill_cut_execute_2_plot.gif" style="width:100%">
                </div>
            </div>
        </div>
        <p></p>
        <div class="col justify-content-center text-center">
            <h3>Compare with baselines</h3>
        </div>
        <div class="row align-items-center">
            <div class="col-md-6">
                <div class="col justify-content-center text-center">
                    <h5>Model-free RL (SAC)</h5>
                    <div class="row align-items-center">
                        <div class="col-md-4">
                            <img src="img/baseline_sac/cut_sac_tool_a.gif" style="width:100%">
                            <h6>Tool A only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_sac/cut_sac_tool_b.gif" style="width:100%">
                            <h6>Tool B only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_sac/cut_sac_tool_ab.gif" style="width:100%">
                            <h6>Multi-tool</h6>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="col justify-content-center text-center">
                    <h5>Trajectory Optimizer (Oracle)</h5>
                    <div class="row align-items-center">
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/cut_traj_opt_tool_a.gif" style="width:100%">
                            <h6>Tool A only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/cut_traj_opt_tool_b.gif" style="width:100%">
                            <h6>Tool B only</h6>
                        </div>
                        <div class="col-md-4">
                            <img src="img/baseline_traj_opt/cut_traj_opt_ab.gif" style="width:100%">
                            <h6>Multi-tool</h6>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


<!--    <div class="section">-->
<!--        <h2>Representing images</h2>-->
<!--        <hr>-->
<!--        <p>-->
<!--            A Siren that maps 2D pixel coordinates to a color may be used to parameterize images. Here, we supervise-->
<!--            Siren-->
<!--            directly with ground-truth pixel values. Siren not only fits the image with a 10 dB higher PSNR and in-->
<!--            significantly-->
<!--            fewer iterations than all baseline architectures, but is also the only MLP that accurately represents the-->
<!--            first- -->
<!--            and second order derivatives of the image.-->
<!--        </p>-->
<!--        <div class="row align-items-center">-->
<!--            <div class="col justify-content-center text-center">-->
<!--                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">-->
<!--                    <source src="img/image_convergence_15s_label.mp4" type="video/mp4">-->
<!--                </video>-->
<!--            </div>-->
<!--        </div>-->
<!--        <div class="row align-items-center">-->
<!--            <div class="col justify-content-center text-center">-->
<!--                <video width="40%" playsinline="" autoplay="" loop="" preload="" muted="">-->
<!--                    <source src="img/psnr_image_convergence_15s.mp4" type="video/mp4">-->
<!--                </video>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Representing Audio</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            A Siren with a single, time-coordinate input and scalar output may parameterize audio signals. Siren is the-->
    <!--            only network architecture that succeeds in reproducing the audio signal, both for music and human voice.-->
    <!--        </p>-->
    <!--        <div class="row justify-content-left">-->
    <!--            <div class="col-sm-3">-->
    <!--                <h5>Ground truth</h5>-->
    <!--                <img src="img/audio/gt_bach.png" style="width:100%">-->
    <!--                <audio-->
    <!--                        controls-->
    <!--                        src="img/audio/gt_bach.wav"-->
    <!--                        class="media-left"-->
    <!--                        style="width:100%">-->
    <!--                    Your browser does not support the-->
    <!--                    <code>audio</code> element.-->
    <!--                </audio>-->
    <!--            </div>-->
    <!--            <div class="col-sm-3">-->
    <!--                <h5>ReLU MLP</h5>-->
    <!--                <img src="img/audio/relu_bach.png" style="width:100%">-->
    <!--                <audio-->
    <!--                        controls-->
    <!--                        src="img/audio/relu_bach.wav"-->
    <!--                        class="media-left"-->
    <!--                        style="width:100%">-->
    <!--                    Your browser does not support the-->
    <!--                    <code>audio</code> element.-->
    <!--                </audio>-->
    <!--            </div>-->
    <!--            <div class="col-sm-3">-->
    <!--                <h5>ReLU w/ Pos. Enc.</h5>-->
    <!--                <img src="img/audio/relu_pe_bach.png" style="width:100%">-->
    <!--                <audio-->
    <!--                        controls-->
    <!--                        src="img/audio/relu_pe_bach.wav"-->
    <!--                        class="media-left"-->
    <!--                        style="width:100%">-->
    <!--                    Your browser does not support the-->
    <!--                    <code>audio</code> element.-->
    <!--                </audio>-->
    <!--            </div>-->
    <!--            <div class="col-sm-3">-->
    <!--                <h5>Siren</h5>-->
    <!--                <img src="img/audio/siren_bach.png" style="width:100%">-->
    <!--                <audio-->
    <!--                        controls-->
    <!--                        src="img/audio/siren_bach.wav"-->
    <!--                        class="media-left"-->
    <!--                        style="width:100%">-->
    <!--                    Your browser does not support the-->
    <!--                    <code>audio</code> element.-->
    <!--                </audio>-->
    <!--            </div>-->

    <!--            <div class="row justify-content-left">-->
    <!--                <div class="col-sm-3">-->
    <!--&lt;!&ndash;                    <h5>Ground truth</h5>&ndash;&gt;-->
    <!--                    <img src="img/audio/gt_counting.png" style="width:100%">-->
    <!--                    <audio-->
    <!--                            controls-->
    <!--                            src="img/audio/gt_counting.wav"-->
    <!--                            class="media-left"-->
    <!--                            style="width:100%">-->
    <!--                        Your browser does not support the-->
    <!--                        <code>audio</code> element.-->
    <!--                    </audio>-->
    <!--                </div>-->
    <!--                <div class="col-sm-3">-->
    <!--&lt;!&ndash;                    <h5>ReLU MLP</h5>&ndash;&gt;-->
    <!--                    <img src="img/audio/relu_counting.png" style="width:100%">-->
    <!--                    <audio-->
    <!--                            controls-->
    <!--                            src="img/audio/relu_counting.wav"-->
    <!--                            class="media-left"-->
    <!--                            style="width:100%">-->
    <!--                        Your browser does not support the-->
    <!--                        <code>audio</code> element.-->
    <!--                    </audio>-->
    <!--                </div>-->
    <!--                <div class="col-sm-3">-->
    <!--&lt;!&ndash;                    <h5>ReLU P.E.</h5>&ndash;&gt;-->
    <!--                    <img src="img/audio/relu_pe_counting.png" style="width:100%">-->
    <!--                    <audio-->
    <!--                            controls-->
    <!--                            src="img/audio/relu_pe_counting.wav"-->
    <!--                            class="media-left"-->
    <!--                            style="width:100%">-->
    <!--                        Your browser does not support the-->
    <!--                        <code>audio</code> element.-->
    <!--                    </audio>-->
    <!--                </div>-->
    <!--                <div class="col-sm-3">-->
    <!--&lt;!&ndash;                    <h5>Siren</h5>&ndash;&gt;-->
    <!--                    <img src="img/audio/siren_counting.png" style="width:100%">-->
    <!--                    <audio-->
    <!--                            controls-->
    <!--                            src="img/audio/siren_counting.wav"-->
    <!--                            class="media-left"-->
    <!--                            style="width:100%">-->
    <!--                        Your browser does not support the-->
    <!--                        <code>audio</code> element.-->
    <!--                    </audio>-->
    <!--                </div>-->
    <!--        </div>-->
    <!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Representing Video</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            A Siren with pixel coordinates together with a time coordinate can be used to parameterize a video.-->
    <!--            Here, Siren is directly supervised with the ground-truth pixel values, and parameterizes video significantly-->
    <!--            better than a ReLU MLP.-->
    <!--        </p>-->
    <!--        <div class="row align-items-center">-->
    <!--            <div class="col justify-content-center text-center">-->
    <!--                <video width="50%" playsinline="" autoplay="" loop="" preload="" muted="">-->
    <!--                    <source src="img/cat_comparison_label.mp4" type="video/mp4">-->
    <!--                </video>-->
    <!--            </div>-->
    <!--            <div class="col justify-content-center text-center">-->
    <!--                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">-->
    <!--                    <source src="img/bikes_comparison_label.mp4" type="video/mp4">-->
    <!--                </video>-->
    <!--            </div>-->
    <!--        </div>-->
    <!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Solving the Poisson Equation</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            By supervising only the derivatives of Siren, we can solve <a href="https://en.wikipedia.org/wiki/Poisson%27s_equation">Poisson's equation</a>.-->
    <!--            Siren is again the only architecture that fits image, gradient, and laplacian domains accurately and swiftly.-->
    <!--        </p>-->
    <!--         <div class="row align-items-center">-->
    <!--            <div class="col justify-content-center text-center">-->
    <!--                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">-->
    <!--                    <source src="img/poisson_convergence_15s_label.mp4" type="video/mp4">-->
    <!--                </video>-->
    <!--            </div> -->
    <!--        </div>-->
    <!--        <div class="row align-items-center">-->
    <!--			<div class="col justify-content-center text-center">-->
    <!--                <video width="40%" playsinline="" autoplay="" loop="" preload="" muted="">-->
    <!--                    <source src="img/psnr_poisson_convergence_15s.mp4" type="video/mp4">-->
    <!--                </video>-->
    <!--            </div> -->
    <!--        </div>-->
    <!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Representing shapes by solving the Eikonal equation<br>-->
    <!--            Interactive 3D SDF Viewer - Use Your Mouse to Navigate the Scenes</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            We can recover an SDF from a pointcloud and surface normals by solving the <a-->
    <!--                href="https://www.google.com/search?client=ubuntu&channel=fs&q=eikonal+equation&ie=utf-8&oe=utf-8">Eikonal-->
    <!--            equation</a>,-->
    <!--            a first-order boundary value problem. SIREN can recover a room-scale scene given only its pointcloud-->
    <!--            and surface normals, accurately reproducing fine detail, in less than an hour of training.-->
    <!--            In contrast to recent work on combining voxel grids with neural implicit representations,-->
    <!--            this stores the full scene in the weights of a single, 5-layer neural network, with no 2D or 3D-->
    <!--            convolutions, and orders of magnitude fewer parameters. Zoom in to compare fine detail!-->
    <!--            <b>Note that these SDFs are not supervised with ground-truth SDF / occupancy values, but rather, are the-->
    <!--            result of solving the above Eikonal boundary value problem. This is a significantly harder task,-->
    <!--            which requires supervision in the gradient domain (see paper). As a result, architectures whose gradients-->
    <!--            are not well-behaved perform worse than SIREN.</b>-->
    <!--        </p>-->
    <!--        <div class="container">-->
    <!--            <div class="row align-items-center">-->
    <!--                <div class="col-md-6 padding-0 canvas-row">-->
    <!--                    <h4>Room - Siren</h4>-->
    <!--                    <model-viewer-->
    <!--                            alt="Room Siren"-->
    <!--                            src="img/room_siren.glb"-->
    <!--                            style="width: 100%; height:300px; background-color: #404040"-->
    <!--                            exposure=".8"-->
    <!--                            camera-orbit="0deg 75deg 105%"-->
    <!--                            auto-rotate-->
    <!--                            camera-controls>-->
    <!--                    </model-viewer>-->
    <!--                </div>-->
    <!--                <div class="col-md-6 padding-0 canvas-row">-->
    <!--                    <h4>Room - ReLU</h4>-->
    <!--                    <model-viewer-->
    <!--                            alt="Room ReLU"-->
    <!--                            src="img/room_relu.glb"-->
    <!--                            style="width: 100%; height: 300px; background-color: #404040"-->
    <!--                            exposure=".8"-->
    <!--                            auto-rotate-->
    <!--                            camera-controls>-->
    <!--                    </model-viewer>-->
    <!--                    &lt;!&ndash;                            poster="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5e7e6db2d75a9b467eee4111_legomesh_cover.png"&ndash;&gt;-->
    <!--                </div>-->
    <!--            </div>-->
    <!--            <div class="row align-items-center">-->
    <!--                <div class="col-md-4 padding-0 canvas-row">-->
    <!--                    <h4>Statue - Siren</h4>-->
    <!--                    <model-viewer-->
    <!--                            alt="Statue Siren"-->
    <!--                            src="img/statue_siren.glb"-->
    <!--                            style="width: 100%; height: 600px; background-color: #404040"-->
    <!--                            exposure=".8"-->
    <!--                            camera-orbit="0deg 75deg 20%"-->
    <!--                            auto-rotate-->
    <!--                            camera-controls>-->
    <!--                    </model-viewer>-->
    <!--                </div>-->
    <!--                <div class="col-md-4 padding-0 canvas-row">-->
    <!--                    <h4>Statue - ReLU Pos. Enc.</h4>-->
    <!--                    <model-viewer-->
    <!--                            alt="Statue Positional Encoding"-->
    <!--                            src="img/statue_relu_pe.glb"-->
    <!--                            style="width: 100%; height: 600px; background-color: #404040"-->
    <!--                            exposure=".8"-->
    <!--                            camera-orbit="0deg 75deg 20%"-->
    <!--                            auto-rotate-->
    <!--                            camera-controls>-->
    <!--                    </model-viewer>-->
    <!--                </div>-->
    <!--                <div class="col-md-4 padding-0 canvas-row">-->
    <!--                    <h4>Statue - ReLU</h4>-->
    <!--                    <model-viewer-->
    <!--                            alt="Statue ReLU"-->
    <!--                            src="img/statue_relu.glb"-->
    <!--                            style="width: 100%; height: 600px; background-color: #404040"-->
    <!--                            exposure=".8"-->
    <!--                            camera-orbit="0deg 75deg 20%"-->
    <!--                            auto-rotate-->
    <!--                            camera-controls>-->
    <!--                    </model-viewer>-->
    <!--                </div>-->
    <!--            </div>-->
    <!--        </div>-->

    <!--        &lt;!&ndash; Loads <model-viewer> for modern browsers: &ndash;&gt;-->
    <!--        <script type="module"-->
    <!--                src="https://unpkg.com/@google/model-viewer/dist/model-viewer.js">-->
    <!--        </script>-->
    <!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Solving the Helmholtz equation</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            Here, we use Siren to solve the <a href="https://en.wikipedia.org/wiki/Helmholtz_equation">inhomogeneous Helmholtz equation</a>.-->
    <!--            ReLU- and Tanh-based architectures fail entirely to converge to a solution.-->
    <!--        </p>-->
    <!--        <div class="gif">-->
    <!--            <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">-->
    <!--                <source src="img/helmholtz_convergence_video_pad_label.mp4" type="video/mp4">-->
    <!--            </video>-->
    <!--        </div>-->
    <!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Solving the wave equation</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            In the time domain, Siren succeeds to solve the wave equation, while a Tanh-based architecture fails to discover the-->
    <!--            correct solution.-->
    <!--        </p>-->
    <!--        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="" class="gif">-->
    <!--            <source src="img/wave_combined_pad_label.mp4" type="video/mp4">-->
    <!--        </video>-->
    <!--    </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Related Projects</h2>-->
    <!--        <hr>-->
    <!--        <p>-->
    <!--            Check out our related projects on the topic of implicit neural representations! <br>-->
    <!--        </p>-->
    <!--        <div class='row vspace-top'>-->
    <!--            <div class="col-sm-3">-->
    <!--                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">-->
    <!--                    <source src="img/metasdf_steps_comp.mp4" type="video/mp4">-->
    <!--                </video>-->
    <!--            </div>-->

    <!--            <div class="col">-->
    <!--                <div class='paper-title'>-->
    <!--                    <a href="http://vsitzmann.github.io/metasdf/">MetaSDF: Meta-learning Signed Distance Functions</a>-->
    <!--                </div>-->
    <!--                <div>-->
    <!--                    We identify a key relationship between generalization across implicit neural representations and meta- -->
    <!--                    learning, and propose to leverage gradient-based meta-learning for learning priors over deep signed distance-->
    <!--                    functions. This allows us to reconstruct SDFs an order of magnitude faster than the auto-decoder framework,-->
    <!--                    with no loss in performance!-->
    <!--                </div>-->
    <!--            </div>-->
    <!--        </div>-->

    <!--        <div class='row vspace-top'>-->
    <!--            <div class="col-sm-3">-->
    <!--                <img src='img/SRNs.gif' class='img-fluid'>-->
    <!--            </div>-->

    <!--            <div class="col">-->
    <!--                <div class='paper-title'>-->
    <!--                    <a href="http://vsitzmann.github.io/srns/">Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations</a>-->

    <!--                </div>-->
    <!--                <div>-->
    <!--                    A continuous, 3D-structure-aware neural scene representation that encodes both geometry and appearance,-->
    <!--                    supervised only in 2D via a neural renderer, and generalizes for 3D reconstruction from a single posed 2D image.-->
    <!--                </div>-->
    <!--            </div>-->
    <!--        </div>-->

    <!--        <div class='row vspace-top'>-->
    <!--            <div class="col-sm-3">-->
    <!--                <img src='img/srn_seg_repimage.jpg' class='img-fluid'>-->
    <!--            </div>-->

    <!--            <div class="col">-->
    <!--                <div class='paper-title'>-->
    <!--                    <a href="https://www.computationalimaging.org/publications/semantic-srn/">Inferring Semantic Information with 3D Neural Scene Representations-->
    <!--                    </a>-->
    <!--                </div>-->
    <!--                <div>-->
    <!--                    We demonstrate that the features learned by neural implicit scene representations are useful for downstream-->
    <!--                    tasks, such as semantic segmentation, and propose a model that can learn to perform continuous 3D-->
    <!--                    semantic segmentation on a class of objects (such as chairs) given only a single, 2D (!) semantic label map!-->
    <!--                </div>-->
    <!--            </div>-->
    <!--        </div>-->

    <!--    <div class="section">-->
    <!--        <h2>Paper</h2>-->
    <!--        <hr>-->
    <!--        <div>-->
    <!--            <div class="list-group">-->
    <!--                <a href="https://arxiv.org/abs/2006.09661"-->
    <!--                   class="list-group-item">-->
    <!--                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">-->
    <!--                </a>-->
    <!--            </div>-->
    <!--        </div>-->
    <!--    </div>-->

        <div class="section">
            <h2>Bibtex</h2>
            <hr>
            <div class="bibtexsection">
                @inproceedings{lin2022diffskill,
                    author = {Lin, Xingyu and Huang, Zhiao and Li, Yunzhu and
                              Tenenbaum, Joshua B. and Held, David and Gan, Chuang},
                    title = {DiffSkill: Skill Abstraction from Differentiable Physics
                             for Deformable Object Manipulations with Tools},
                    journal={International Conference on Learning Representation (ICLR)},
                    year={2022}}
            </div>
        </div>

    <!--    <hr>-->

    <!--    <footer>-->
    <!--        <p>Send feedback and questions to <a href="http://web.stanford.edu/~sitzmann/">Vincent Sitzmann</a></p>-->
    <!--    </footer>-->
    <!--</div>-->


    <!--<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"-->
    <!--        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"-->
    <!--        crossorigin="anonymous"></script>-->
    <!--<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"-->
    <!--        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"-->
    <!--        crossorigin="anonymous"></script>-->
    <!--<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"-->
    <!--        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"-->
    <!--        crossorigin="anonymous"></script>-->

</body>
</html>
